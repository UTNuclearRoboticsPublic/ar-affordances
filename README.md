# AR-Based Contact Task Demonstrations

[![YouTube Demonstration Video](https://user-images.githubusercontent.com/84527482/222321638-8ced7798-70ca-40a6-8df2-5a5c11380408.png)](https://www.youtube.com/watch?v=5AKIhkXAiO4&ab_channel=Nuclear%26AppliedRoboticsGroup)

## About
This is a novel end-to-end system that captures a single manipulation task demonstration from an augmented reality (AR) head-mounted display (HMD), computes an affordance primitive (AP) representation of the task, and sends the task parameters to a mobile manipulator for execution in real-time. The system is robust, generalizable, and mobile and is intended for non-expert users to be able to define manipulator contact tasks in unknown and unstructured environments on the fly without requiring environment modifications. To learn more, watch the demonstration video hyperlinked below or watch our presentation at the 2023 IEEE IROS Conference in Detroit, MI. 

## System Setup
* [AR-HMD](arhmd/README.md)
* [Robot](robot/README.md)
* [Server](server/README.md)

## Citation
```
@inproceedings{regalUsingSingleDemonstrations2023,
  title = {Using Single Demonstrations to Define Autonomous Manipulation
  Contact Tasks in Unstructured Environments via Object Affordances},
  author = {Regal, Frank and Pettinger, Adam and Duncan, John and Parra, Fabian
  and Akita, Emmanuel and Navarro, Alex and Pryor, Mitch},
  booktitle = {IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={},
  year = {2023},
  organization={IEEE}
}
```
